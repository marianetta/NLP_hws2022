{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc1cdbe",
   "metadata": {},
   "source": [
    "### 1. Про корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1f003",
   "metadata": {},
   "source": [
    "корпус и описание трудных моментов -- в файле \n",
    "\n",
    "корпус с разметкой, который я использовала для золотого стандарта -- в файле 'copied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "5ada4418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy in c:\\users\\maria\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\maria\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (1.22.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (8.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (1.9.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\maria\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting ru-core-news-md==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.4.0/ru_core_news_md-3.4.0-py3-none-any.whl (41.9 MB)\n",
      "Requirement already satisfied: pymorphy2>=0.9 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from ru-core-news-md==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from ru-core-news-md==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-md==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-md==3.4.0) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-md==3.4.0) (0.7.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (8.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (1.22.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (3.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (0.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\maria\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-md==3.4.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('ru_core_news_md')\n",
      "Requirement already satisfied: stanza in c:\\users\\maria\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: six in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (1.22.4)\n",
      "Requirement already satisfied: emoji in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (2.1.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\maria\\anaconda3\\lib\\site-packages (from stanza) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\maria\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->stanza) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->stanza) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\maria\\anaconda3\\lib\\site-packages (from requests->stanza) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\maria\\anaconda3\\lib\\site-packages (from tqdm->stanza) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy\n",
    "!pip install spacy\n",
    "!python -m spacy download ru_core_news_md\n",
    "!pip install stanza\n",
    "import stanza\n",
    "import spacy\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "07d73eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4910c",
   "metadata": {},
   "source": [
    "### 2. Три теггера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "e0c161d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# списки для тегов\n",
    "pos_pymorphy = []\n",
    "pos_spacy = []\n",
    "pos_stanza = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "a29cf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymorphy\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "morph = MorphAnalyzer()\n",
    "for token in tokenized:\n",
    "    pos = morph.parse(token)[0].tag.POS\n",
    "    if pos != None:\n",
    "        # pymorphy выделяет отдельны1 тег для сравнительной степени\n",
    "        if pos == \"COMP\":     # перевожу теги COMP в наречие/прилагательное\n",
    "            g = morph.parse(token)[0].tag.gender\n",
    "            if g == 'masc' or g == 'femn' or g == 'neut':  \n",
    "                pos = 'ADJF'\n",
    "            else:\n",
    "                pos = 'ADVB'\n",
    "        pos_pymorphy.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "cb1287d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy\n",
    "m_sp = spacy.load('ru_core_news_md')\n",
    "text_sp = m_sp(text)\n",
    "for token in text_sp:\n",
    "    if token.pos_ != 'PUNCT':            \n",
    "        pos_spacy.append(token.pos_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "f5473028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 22:49:55 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04002261161804199,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json",
       "rate": null,
       "total": 28896,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463e586e4a9b4570a26fadeaf82a1bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 22:49:57 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "=========================\n",
      "\n",
      "2022-10-11 22:49:57 INFO: Use device: cpu\n",
      "2022-10-11 22:49:57 INFO: Loading: tokenize\n",
      "2022-10-11 22:49:57 INFO: Loading: pos\n",
      "2022-10-11 22:49:57 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# stanza\n",
    "m_st = stanza.Pipeline('ru', processors='tokenize,pos')\n",
    "text_st = m_st(text)\n",
    "for sentence in text_st.sentences:\n",
    "    for token in sentence.words:\n",
    "        if token.pos != 'PUNCT':\n",
    "            pos_stanza.append(token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "1123b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# золотой стандарт (список тегов)\n",
    "with open('copied', 'r', encoding='utf-8') as f2:\n",
    "    allt = f2.read()\n",
    "pos_gold = list(allt.split('\\n'))[1::2][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7313a9a",
   "metadata": {},
   "source": [
    "### 3. Сведение к одному стандарту, оценка accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "06055363",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(pos_pymorphy):\n",
    "    if p == 'ADJF':\n",
    "        pos_pymorphy[i] = 'ADJ'\n",
    "    if p == 'ADVB':\n",
    "        pos_pymorphy[i] = 'ADV'\n",
    "    if p == 'GRND':\n",
    "        pos_pymorphy[i] = 'VERB'\n",
    "    if p == 'INFN':\n",
    "        pos_pymorphy[i] = 'VERB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "38c47976",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(pos_spacy):\n",
    "    if p == 'DET':\n",
    "        pos_spacy[i] = 'ADJ'\n",
    "    if p == 'CCONJ':\n",
    "        pos_spacy[i] = 'CONJ'\n",
    "    if p == 'SCONJ':\n",
    "        pos_spacy[i] = 'CONJ'\n",
    "    if p == 'PRON':\n",
    "        pos_spacy[i] = 'NPRO'\n",
    "    if p == 'PART':\n",
    "        pos_spacy[i] = 'PRCL'\n",
    "    if p == 'ADP':\n",
    "        pos_spacy[i] = 'PREP'\n",
    "    if p == 'AUX':\n",
    "        pos_spacy[i] = 'VERB'\n",
    "    if p == 'PROPN':\n",
    "        pos_spacy[i] = 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "a7cb08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(pos_stanza):\n",
    "    if p == 'DET':\n",
    "        pos_stanza[i] = 'ADJ'\n",
    "    if p == 'CCONJ':\n",
    "        pos_stanza[i] = 'CONJ'\n",
    "    if p == 'SCONJ':\n",
    "        pos_stanza[i] = 'CONJ'\n",
    "    if p == 'PRON':\n",
    "        pos_stanza[i] = 'NPRO'\n",
    "    if p == 'PART':\n",
    "        pos_stanza[i] = 'PRCL'\n",
    "    if p == 'ADP':\n",
    "        pos_stanza[i] = 'PREP'\n",
    "    if p == 'PROPN':\n",
    "        pos_stanza[i] = 'NOUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "e6250595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "e4a81604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pos_gold, pos_pymorphy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "727740a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9155555555555556"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pos_gold, pos_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "d2db0514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pos_gold, pos_stanza)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe165ca",
   "metadata": {},
   "source": [
    "самая высокая accuracy -- у spacy, он используется в следующем пункте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4423edb",
   "metadata": {},
   "source": [
    "### 4. Создание чанкера\n",
    "Используются шаблоны:\n",
    "1) не + ADJ; не + VERB -- качество должно улучшиться, потому что учитывается отрицание\n",
    "\n",
    "2) нет + NOUN -- качество должно улучшиться, потому что учитывается отрицание\n",
    "\n",
    "3) VERB + но; ADJ + но -- качество должно улучшиться, потому что после но обычно идет противоположная информация (тоже вроде учета отрицания)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "52e8dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_chunker(text):\n",
    "    tokens = {}\n",
    "    poses = {}\n",
    "    text_sp = m_sp(text)\n",
    "    c = 0\n",
    "    chunks_adjs = []\n",
    "    chunks_verbs = []\n",
    "    chunks_nouns = []\n",
    "    but_verbs = []\n",
    "    but_adjs = []\n",
    "    for token in text_sp:\n",
    "        if token.pos_ != 'PUNCT':            \n",
    "            tokens[c] = token\n",
    "            poses[c] = [token.pos_]\n",
    "            c += 1\n",
    "    for k in range(len(tokens.keys()) - 1):\n",
    "        if (str(tokens[k]) == 'не') and (str(poses[k+1][0]) == 'ADJ'):\n",
    "            chunk = str(tokens[k]) + ' ' + str(tokens[k+1])\n",
    "            chunks_adjs.append(chunk)\n",
    "        if (str(tokens[k]) == 'не') and (str(poses[k+1][0]) == 'VERB'):\n",
    "            chunk = str(tokens[k]) + ' ' + str(tokens[k+1])\n",
    "            chunks_verbs.append(chunk)\n",
    "        if (str(tokens[k]) == 'нет') and (str(poses[k+1][0]) == 'NOUN'):\n",
    "            chunk = str(tokens[k]) + ' ' + str(tokens[k+1])\n",
    "            chunks_nouns.append(chunk)\n",
    "        if (str(poses[k][0]) == 'VERB') and (str(tokens[k+1]) == 'но'):\n",
    "            chunk = str(tokens[k]) + ' ' + str(tokens[k+1])\n",
    "            but_verbs.append(chunk)\n",
    "        if (str(poses[k][0]) == 'ADJ') and (str(tokens[k+1]) == 'но'):\n",
    "            chunk = str(tokens[k]) + ' ' + str(tokens[k+1])\n",
    "            but_adjs.append(chunk)\n",
    "    chunks = chunks_adjs + chunks_verbs + chunks_nouns + but_verbs + but_adjs\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa584f",
   "metadata": {},
   "source": [
    "### 4 Изменение первой домашки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4430a",
   "metadata": {},
   "source": [
    "как было "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "945ddd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "e96d85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_neg = ['https://otzov-mf.ru/napitok-energeticheskij-red-bull-otzyvy/', \n",
    "             'https://otzov-mf.ru/energeticheskij-napitok-flash-energy-otzyvy/', \n",
    "             'https://otzov-mf.ru/napitok-energeticheskij-strike-otzyvy/',\n",
    "             'https://otzov-mf.ru/energeticheskij-napitok-ten-strike-sky-otzyvy/']\n",
    "\n",
    "\n",
    "links_pos = ['https://otzov-mf.ru/napitok-energeticheskij-red-bull-otzyvy/', \n",
    "             'https://otzov-mf.ru/energeticheskij-napitok-flash-energy-otzyvy/', \n",
    "             'https://otzov-mf.ru/napitok-energeticheskij-strike-otzyvy/']\n",
    "# 33 отрицательных, 32 положительных\n",
    "\n",
    "text_neg = ''\n",
    "text_pos = ''\n",
    "\n",
    "for ln in links_neg:\n",
    "    page = requests.get(ln)\n",
    "    text = page.text\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    soup_neg = soup.find('div',{'class':'itric'})\n",
    "    texts_neg = soup_neg.find_all('p')\n",
    "    for t in texts_neg:\n",
    "        text_neg = text_neg + ' ' + t.text.strip().strip(punctuation) + \" \"\n",
    "\n",
    "\n",
    "link_patt = re.compile('ht[tps]+://[^А-я]+')\n",
    "links = re.findall(link_patt, text_neg)\n",
    "for l in links:\n",
    "    text_neg = text_neg.replace(l, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "818a5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_neg = nltk.word_tokenize(text_neg)\n",
    "words_neg = [word.lower() for word in l_neg if word.isalpha()]\n",
    "lemmas_neg = []\n",
    "morph = MorphAnalyzer()\n",
    "for form in words_neg:\n",
    "    first = morph.parse(form)[0]\n",
    "    lemmas_neg.append(first.normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "44b4c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lp in links_pos:\n",
    "    page = requests.get(lp)\n",
    "    text = page.text\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    soup_pos = soup.find('div',{'class':'pozitive'})\n",
    "    texts_pos = soup_pos.find_all('p')\n",
    "    for t in texts_pos:\n",
    "        text_pos = text_pos + ' ' + t.text.strip().strip(punctuation) + \" \"\n",
    "\n",
    "link_patt = re.compile('ht[tps]+://[^А-я]+')\n",
    "links = re.findall(link_patt, text_pos)\n",
    "for l in links:\n",
    "    text_pos = text_pos.replace(l, '')\n",
    "    text_pos = text_pos.replace('http://відгук.укр/ru/напиток_энергетический_red_bull-r129764.html', '')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "a27ff432",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pos = nltk.word_tokenize(text_pos)\n",
    "words_pos = [word.lower() for word in l_pos if word.isalpha()]\n",
    "lemmas_pos = []\n",
    "morph = MorphAnalyzer()\n",
    "for form in words_pos:\n",
    "    first = morph.parse(form)[0]\n",
    "    lemmas_pos.append(first.normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "e9ef5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter_pos = Counter(lemmas_pos)\n",
    "counter_pos2 = {k:counter_pos[k] for k in counter_pos if counter_pos[k] > 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "eb6cda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_neg = Counter(lemmas_neg)\n",
    "counter_neg2 = {k:counter_neg[k] for k in counter_neg if counter_neg[k] > 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "701ca54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_pos = set(counter_pos2.keys())\n",
    "set_neg = set(counter_neg2.keys())\n",
    "only_pos = set_pos - set_neg\n",
    "only_neg = set_neg - set_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "cb190011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ton_de(text):\n",
    "    cp = 0\n",
    "    cn = 0\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for w in words:  # для слов \n",
    "        if w in only_pos:\n",
    "            cp += 1\n",
    "        if w in only_neg:\n",
    "            cn += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_for_b = [word.lower().strip(punctuation) for word in text.split(' ') if word.isalpha()] # для биграм\n",
    "    bigrams = nltk.bigrams(t_for_b)\n",
    "    my_bigrams = []\n",
    "    for b in list(bigrams):\n",
    "        list_b = []\n",
    "        for i in range(len(list(b))):\n",
    "            first = morph.parse(list(b)[i])[0]\n",
    "            lemma = first.normal_form\n",
    "            list_b.append(lemma)\n",
    "            lemmas = ' '.join(list_b)\n",
    "        my_bigrams.append(lemmas)\n",
    "    for bigram in my_bigrams:\n",
    "        if bigram in only_pos:\n",
    "            cp += 1\n",
    "        if bigram in only_neg:\n",
    "            cn += 1\n",
    "            \n",
    "    if cn > cp:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "eb212cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = ['''Доброго времени суток обитателям Айрекоменда\n",
    "Я все еще нахожусь в поисках идеального энергетика для себя, хоть и понимаю, что пользы от таких напитков никакой нет, но все знают ситуации, когда нужно успеть сделать миллион дел, но энергии совсем нет. Сегодня речь пойдет об энергетике Торнадо Актив.\n",
    "Место покупки - супермаркет \"Ярче!\"\n",
    "Цена - 30 рублей\n",
    "Приехав с учебы я осознала, что энергии после 5 пар у меня не осталось, а впереди предстояла бессонная ночь в попытках написать хотя бы малую часть курсовой работы, думаю такая или подобная ситуация знакома многим. Зашла по пути домой в супермаркет и направилась к полке с энергетиками, и взяв пару разных направилась на кассу.\n",
    "Придя домой я глазами пробежалась по упаковке\n",
    "Состав не самый плохой.\n",
    "Я открыла банку и уловила уже до боли знакомый аромат. Так пахнут большинство энергетиков.\n",
    "Цвет - как у фанты\n",
    "Вкус - ну как сказать... типичный для энергетика, ничего нового и необычного я не почувствовала. Газирован не сильно, слизистые не горят. Однако энергетического эффекта я тоже не заметила, опустошив банку я все так же хотела спать и была все такой же уставшей. Крайне не рекомендую этот энергетик, если уж травить организм, то тем энергетиком который работает, а не этой пустышкой\n",
    "''', \n",
    "'''Достоинства:\n",
    "Цена, и то по акции\n",
    "Недостатки:\n",
    "Вкус, состав, все одним словом\n",
    "Энергетики до этого никогда не брала. Пару раз пробовала, не очень понравилось, сладко и бееее.\n",
    "Но тут зашла в \"Магазинчик\", а там акция на него, ну и я такая: \"Ну возьму, была ни была\". Взяла, на кассе на меня ооочень косо смотрели но продали. По акции банка 0.45 л стоило, кажется, 28 или 29. Точно не помню)\n",
    "Вышла я такая на каблуках, в платюшке 15 лет) и с банкой \"Tornado\" в руках)\n",
    "О вкусе: слишком химически кисло, слишком апельсиново, слишком кисло-сладко\n",
    "Мне не понравилось( выпила совсееем немного (просто пить хотелось очень\n",
    "сильно) и выкинула гораздо больше половины.\n",
    "Взяла и пожалела. Всем любителям \"Tornado\" -- советую, всем остальным -- не очень)\n",
    "Извините, что так долго не появлялась( не было настроения, желания, бабушки болели, одна до сих пор в больнице лежит...\n",
    "''',\n",
    "'''Достоинства:\n",
    "Их нет и быть не может\n",
    "Недостатки:\n",
    "Убивает организм эта дрянь\n",
    "Подробности:\n",
    "Я наблюдательный человек и очень критичный, я много времени гуляю с ребенком при хорошей погоде и замечаю, что каждый третий подросток сидит курит и пьет ягуар ну конечно делать им то нечего гроб ят свое здоровье и молодость, но у меня только один вопрос зачем?? ведь они так молоды, да я знаю многие читая это подумают да нашлась тоже тут советчица, но поймите придет время вы захотите семью, детей, но ваш ь организм уже не сможет справится со всем, не губ те себя этими ягуар ами, производителю все ровно вас ему интересны вышли деньги и его рейтенги и что бы ягуар об ходил с ему дешевле всякой дряни туда напихают, но сами они его не уплотребляют, задумайтесь прежде чем пить этот яд\n",
    "''',\n",
    "'''Мне до сих пор нравиться его вкус,такой резкий и немного кисловатый.Нравилось состояние после выпитой банки,-приподнятое и энергичное.Также привлекала и сама упаковка,немного шероховатая матовая.По доступной цене.Пока не начались проблемы с сердцем и многочисленные рассказы о побочных эффектах данного напитка.Самый запоминающийся был о том,что за ночь ЯГУАР разъедает марлю.Отказалась от него сразу,слава богу без серьезных проблем для здоровья.Знаю,что его давно запретили,но у нас он продается почти в каждом магазине(\n",
    "''',\n",
    "'''Ужасный напиток, который я не рокерскую употреблять никому, он очень сильно действует на организм человека, и от него можно отравится, я знаю много сотен людей которые отравились именно благодаря такому напитку, да стоит он не дорого, но какой вред он приносит организму вы сами подумайте. Что не стоит рисковать свое жизнью ради какого то напитка, который вам хочется выпить, не стоит над эти шутить, над своим здоровьем вообще не не стоит шутить, потому что это очень сильно. Я не понимаю тех людей которые вообще покупают этот напиток, в нем же нету ничего вкусного и полезного, он противный и не вкусный, я иногда просто не понимаю как его можно употреблять ,ведь он не полезен для организма, как его вообще пьют. Не понимаю,вот хоть сколько мне говори. А все равно никогда не пойму тех людей. Которые его употребляют, это не правильно, люди подумайте прежде чем брать данный напиток, подумайте прежде всего о своем здоровье, о том что вы все таки хотите жить а не умереть из за данного напитка, так что как напиток который может сломать жизнь я его не кому не рекомендую, потому что это действительно плохой напиток, который даже не стоит употреблять. И начинать его выпивать, люди подумайте прежде о своем здоровье, а потом уже употребляйте данный напиток.\n",
    "''',\n",
    "'''Достоинства:\n",
    "Расслабляет, поднимает настроение\n",
    "Недостатки:\n",
    "Бывает изжога\n",
    "Вкусный, с друзьями частенько его пьём и ничего, со здоровьем всё отлично. Очень расслабляет и поднимает настроение. Так что мне и знакомым нравится, не вижу ничего в нём плохого.\n",
    "''',\n",
    "'''Достоинства:\n",
    "Вкус.Содержание витамина D.Запах.Приемлемая цена.\n",
    "Недостатки:\n",
    "Энергетики вредные\n",
    "Всем читателям отзыва привет! Сегодня пишу отзыв на энергетический напиток Solar Power. Купил в Пятерочке. Цена за 0.5мл напитка составила 72 рубля -по акции. Цена за объем приемлемая.\n",
    "Вкус грейпфрута, с небольшой кислинкой. В составе, по заверению производителя имеется витамин D, что не может не радовать. Думаю именно из-за содержания витамина D в составе, на энергетике присутствует изображение солнца. Запах цитрусовый, в нос не бьет.\n",
    "Дизайн баночки приятный. Красивый шрифт, солнце с лучами, вообщем прикольно:D Такой энергетик, думаю, не будет сливаться на фоне других. Сама баночка на ощупь приятная, что тоже уходит в плюс.\n",
    "Эффект бодрости по началу даже не заметил, но потом почувствовал. Он приходит со временем, как в энергетике- Жара, если это, конечно, не самовнушение.\n",
    "Всем рекомендую к проде энергетический напиток Solar Power, так как он вкусный и бодрящий, а больше от энергетика и не нужно. Так же стоит помнить, что энергетические напитки вредят вашему здоровью, полезного в них мало. Не стоит с ними злоупотреблять!\n",
    "''',\n",
    "'''Достоинства:\n",
    "Доступность Необычность\n",
    "Недостатки:\n",
    "Не обнаружила\n",
    "Всем привет. Хочу поделиться своим отзывом на энергетический напиток соляр.\n",
    "Как обычно начинаем с доступности. Есть во многих магазинах. Но не во всех. Оценка 7/10\n",
    "Дизайн. Дизайн прикольный. Мне нравится. Но не самый лучший. Моя оценка 6/10\n",
    "И так, цена. Цена на него везде какая то разная, но не больше сотки. В магните по скидону можно купить за 39 рублей. Ну 6/10 моя оценка.\n",
    "И наконец самое интересное. Вкус. Вкус капец какой необычный, не похож ни на один энергетик. По вкусу это странно очень, зайдет далеко не всем, но мне понравилось. Послевкусие есть какого то пива что ли, хз. Блин, с кальмаром или сушёной рыбой это прям круто зайдет. Оценка 7/10\n",
    "Ну общая оценка 6,5/10. Неплохо. По скидону попробуйте. Почему бы и нет.\n",
    "''',\n",
    "'''Достоинства:\n",
    "бодрит сразу просыпаешься\n",
    "Недостатки:\n",
    "иногда и с него спать охота\n",
    "Одно время я работал водителем такси и когда особенно ночью сильно устаешь или хочется сильно спать то ягуар очень выручал в этом вопросе. Мне кажется вкусный ягодный вкус совмещен с тонизирующими свойствами. Очень бодрит но перебарщивать с ним тоже не стоит пить как написано в инструкции.\n",
    "''',\n",
    "'''Люблю пить всякие разные энергетики, самый любимый это - Рэд Булл. Так что сравнение пойдет в параллель с ним. Как не странно вкус абсолютно идентичный, что конечно же делает этому напитку большой плюс. То есть он сладкий, и имеет приятную кислинку, никаких посторонних металлических привкусов не обнаружила.\n",
    "Стоил он 29.90 за 0,5 - это очень отлично, по сравнению с другими ценами за такое количество, сам Рэд Булл стоит за 0,5 , если не ошибаюсь, рублей 80. Ничего особенного не ожидала от покупки, но была приятно удивлена и рада. Напиток очень вкусный, выбрала именно \"Storm\" потому что в его составе было написано меньше всего химической бяки, плюс на баночке заявлены витамины. А так, там было всего три вкуса - \"storm\"(красный), \"ise\"(голубой) \"active\"(оранжевый). Цвет напитка, честно, удивил, очень сильно напомнил пиво, но не тут-то было, кроме цвета, с пивом, этот напиток, не имеет, ровным счетом, ничего общего. По сравнению с прозрачно-желтым Рэдбулловским, этот же будет по-темнее, но ничего сверхъестественного в этом нет, цвет не противный и не специфичный. Похож даже на цвет газировки со вкусом \"ирисок\", если хотите. В меру газированный, пенка была, но не сильная.\n",
    "В общем покупкой довольна, если увижу \"Tornado energy\", то обязательно куплю, попробую другие вкусы, потому что больше смысла переплачивать за Рэд Булл не вижу.\n",
    "Всем рекомендую.\n",
    "Что касается \"прилива сил и энергии\" не могу сказать, потому что энергетики на меня то ли не действуют, то ли я не замечаю, ну в общих чертах, после выпитой баночки носом не клевала до поздней ночи. Решающим фактором для меня при покупке энергетиков, является - вкус, а здесь он на высоте!\n",
    "'''    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "e2fbc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для тестовых я просто накопипастила отзывы, сначала идут 5 отрицательных, потом 5 положительных\n",
    "y_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "15e95146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = []\n",
    "for r in reviews_test:\n",
    "    res = ton_de(r)\n",
    "    y_pred.append(res)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "2e8447c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8823f5",
   "metadata": {},
   "source": [
    "изменение 1 -- добавляем биграммы в множества положительных и отрицательных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "66169e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = my_chunker(' '.join(lemmas_neg) + ' '.join(lemmas_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "dd55713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in chunks:\n",
    "    spl = c.split(' ')\n",
    "    if spl[1] in only_pos:\n",
    "        only_neg.add(c)\n",
    "    if spl[1] in only_neg:\n",
    "        only_pos.add(c)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01358e2d",
   "metadata": {},
   "source": [
    "изменение 2 -- изменяем функцию так, чтобы учитывались биграмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "a0130009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ton_de_new(text):\n",
    "    cp = 0\n",
    "    cn = 0\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for w in words:  # для слов \n",
    "        if w in only_pos:\n",
    "            cp += 1\n",
    "        if w in only_neg:\n",
    "            cn += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    t_for_b = [word.lower().strip(punctuation) for word in text.split(' ') if word.isalpha()] # для биграм\n",
    "    bigrams = nltk.bigrams(t_for_b)\n",
    "    my_bigrams = []\n",
    "    for b in list(bigrams):\n",
    "        list_b = []\n",
    "        for i in range(len(list(b))):\n",
    "            first = morph.parse(list(b)[i])[0]\n",
    "            lemma = first.normal_form\n",
    "            list_b.append(lemma)\n",
    "            lemmas = ' '.join(list_b)\n",
    "        my_bigrams.append(lemmas)\n",
    "    for bigram in my_bigrams:\n",
    "        if bigram in only_pos:\n",
    "            cp += 1\n",
    "        if bigram in only_neg:\n",
    "            cn += 1\n",
    "            \n",
    "    if cn > cp:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "97d4f453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = []\n",
    "for r in reviews_test:\n",
    "    res = ton_de_new(r)\n",
    "    y_pred2.append(res)\n",
    "y_pred\n",
    "accuracy_score(y_pred2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e852bc",
   "metadata": {},
   "source": [
    "accuracy стала ниже.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
